# Analysis

```{r include=FALSE}
library(pander)
library(ggplot2)
load("../data/results.Rdata")
```

### Ordinary Least Squares

For the ordinary least squares regression model, we used the `lm()` function to fit an additive model with all predictors on the training data. We estimated the test mse on the validation set for comparison to the other models, then refit the model on the full data set

### Lasso and Ridge Regression
For the shrinkage methods, we used the package `glmnet`. As mentioned in the Methods section,  these methods work by adding either the l1 or l2 norm of the coefficients to the residuals being minimized. The specific function is controlled by a tuning parameter, $\Lambda$. A higher $\Lambda$ produces smaller coefficients. In order to select the coeffient that strikes the best balance between bias and variance, we perform 10-fold cross validation with the function `cv.glmnet()`. We tried a wide variety of lambda values, and both ridge regression and lasso selected the smallest value, 0.01, as the best.

```{r, out.width = "200px", echo=FALSE}
knitr::include_graphics("../images/Lasso_MSE.png")
knitr::include_graphics("../images/Ridge_MSE.png")
```

*We can see that both methods get the smallest cross-validated MSE at small values of $\Lambda$*

Using this value of lambda, we tried our best model on the test data set to find the test mse by using the function `predict()`, and finding the mean of the squared differences between the predicted outputs and the actual test outputs. We also called the `glmnet()` function to fit the model on the full data set, and used `predict()` again to find the official model coefficients. 


### Principal Components Analysis and Partial Least Squares
For the dimension reduction methods, we used the package `pls`. The functions `pcr()` and `plsr()` were used depending on which regression model we were fitting, with the argument `validation = "CV"` to perform 10-fold cross-validation. In these methods, model selection is based on how many *components* are included in the final model, where each component is a linear combination of the original predictors. We call $validation$PRESS on the output of this function and then find the number of components that yields the lowest mse. For PCR, we selected the full model, but for PLSR, we actually fit a model with only 6 components.

```{r, out.width = "200px", echo=FALSE}
knitr::include_graphics("../images/pcr_validationplot.png")
knitr::include_graphics("../images/plsr_validationplot.png")
```

*Interestingly, PLSR flattens out much more quickly than PCR.*

As with the other models, we estimate the test mse by using the `predict()` function, and refit the model using the full data set with the functions `pcr()` or `plsr()` to find the official model coefficients. 

